# Machine Learning Tasks Repository

Welcome to my Machine Learning Tasks repository! 🚀  
This repo contains a collection of completed machine learning exercises and experiments, implemented in Jupyter Notebooks (.ipynb). Each notebook explores a different aspect of ML — from foundational algorithms to advanced ensemble methods.  

All tasks were completed as part of the *Machine Learning course (minor: Intellectual Data Analysis)* at HSE.  
Each notebook is self-contained; imports are provided inline, and main libraries are also listed in requirements.txt.  

---

## 📂 Repository Structure  

├── ML1_numpy.ipynb  
├── ML2_pandas.ipynb  
├── ML3_EDA.ipynb  
├── ML4_kNN_linreg.ipynb  
├── ML5_GD.ipynb  
├── ML6_text_classification.ipynb  
├── ML7_trees_RF.ipynb  
├── ML8_boosting.ipynb  
├── requirements.txt  
├── LICENSE  
└── README.md  

---

## 📑 Task Overview  

| Notebook | Topic | Key Concepts | Notes |
|----------|-------|--------------|-------|
| ML1_numpy.ipynb | 🔰 NumPy Basics | Arrays, operations, broadcasting | Introductory exercises to get familiar with NumPy. |
| ML2_pandas.ipynb | 📊 Pandas Basics | DataFrames, data manipulation | Basic exercises to learn pandas for tabular data. |
| ML3_EDA.ipynb | 🔎 Exploratory Data Analysis | Credit scoring dataset, visualizations | Worked with 1,000-client dataset (20 features + target), explored credit reliability, visualized distributions, and proposed conditional scoring formula. |
| ML4_kNN_linreg.ipynb | 📈 kNN & Linear Regression | kNN from scratch, Ridge, Lasso | Built kNN algorithm manually, experimented with linear regression and regularization techniques, analyzed results with illustrations. |
| ML5_GD.ipynb | ⚙️ Gradient Descent | Optimization, SGD, simulated annealing | Implemented gradient descent and stochastic gradient descent for linear regression, added MSE and MSEL2 loss, hyperparameter tuning, compared to baseline, also implemented simulated annealing optimization. |
| ML6_text_classification.ipynb | 📝 Text Classification | Tokenizers, tf-idf, hashing trick | Binary classification of tweets about disasters/incidents; tried TweetTokenizer, custom tokenizers, tf-idf, hashing trick; results and visualizations included. |
| ML7_trees_RF.ipynb | 🌳 Trees & Random Forest | Decision tree from scratch, Bagging, Random Forest | Implemented decision tree manually, tested on mushrooms dataset; applied bagging and random forest for diabetes prediction; results and plots provided. |
| ML8_boosting.ipynb | 🚀 Gradient Boosting | XGBoost, LightGBM, CatBoost | Predicted data scientists’ salaries using boosting methods; compared encoding strategies, tuned hyperparameters, concluded lightgbm Regressor showed best performance. |

---

## ⚙️ Setup & Installation  

To run the notebooks locally, you’ll need Python 3.8+ and the dependencies listed in requirements.txt.  

```bash
git clone https://github.com/yourusername/machine-learning-tasks.git
cd machine-learning-tasks
pip install -r requirements.txt
```

Or, open directly in Google Colab.  

---

## 🧑‍💻 Usage  

1. Launch Jupyter Notebook or Jupyter Lab:  

```bash
jupyter notebook
```

2. Open the notebook of interest (e.g., ML1_numpy.ipynb).  
3. Run cells step by step to explore code, results, and commentary.  

---

## 📊 Results & Visualizations  

Each notebook includes:  
 • Explanations of the approach  
 • Training/validation metrics (where applicable)  
 • Key visualizations (distributions, confusion matrices, plots)  
 • Reflections on results and limitations  

---

## 🛠 Dependencies  

Main libraries used across notebooks:  
 • NumPy, Pandas  
 • Matplotlib, Seaborn  
 • scikit-learn  
 • XGBoost, LightGBM, CatBoost  

See requirements.txt for the full list.  

---

## 🌟 Future Work  

Planned extensions:  
 • More tasks on unsupervised learning  
 • Advanced optimization experiments  
 • Larger applied case studies  

---

## 📜 License  

This repository is released under the MIT License.  
Feel free to fork, explore, and build upon it!  

---

## 👤 Author  

Created by [Anastasiia Lapshina](https://github.com/lapshinaaa).  
Feel free to reach out via GitHub Issues if you’d like to collaborate or discuss ideas.  
